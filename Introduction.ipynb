{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Natural Language Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.5\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "doc = nlp(\"Tea is healthy and calming, don't you think?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tokenizing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tea\n",
      "is\n",
      "healthy\n",
      "and\n",
      "calming\n",
      ",\n",
      "do\n",
      "n't\n",
      "you\n",
      "think\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token \t\tLemma \t\tStopword\n",
      "----------------------------------------\n",
      "Tea\t\ttea\t\tFalse\n",
      "is\t\tbe\t\tTrue\n",
      "healthy\t\thealthy\t\tFalse\n",
      "and\t\tand\t\tTrue\n",
      "calming\t\tcalm\t\tFalse\n",
      ",\t\t,\t\tFalse\n",
      "do\t\tdo\t\tTrue\n",
      "n't\t\tnot\t\tTrue\n",
      "you\t\t-PRON-\t\tTrue\n",
      "think\t\tthink\t\tFalse\n",
      "?\t\t?\t\tFalse\n"
     ]
    }
   ],
   "source": [
    "# lemmatize the words\n",
    "print(f\"Token \\t\\tLemma \\t\\tStopword\".format('Token', 'Lemma',\n",
    "                                             'Stopword'))\n",
    "print(\"-\"*40)\n",
    "for token in doc:\n",
    "    print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "# print(matcher)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<spacy.matcher.phrasematcher.PhraseMatcher at 0x19880ca50b0>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = ['Galaxy Note', 'iPhone 11', 'iPhone XS', 'Google Pixel']\n",
    "patterns = [nlp(text) for text in terms]\n",
    "matcher.add(\"TerminologyList\", patterns)\n",
    "matcher"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "text_doc = nlp(\"Glowing review overall, and some really interesting side-by-side \"\n",
    "               \"photography tests pitting the iPhone 11 Pro against the \"\n",
    "               \"Galaxy Note 10 Plus and last yearâ€™s iPhone XS and Google Pixel 3.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3766102292120407359, 17, 19), (3766102292120407359, 22, 24), (3766102292120407359, 30, 32), (3766102292120407359, 33, 35)]\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(text_doc)\n",
    "print(matches)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TerminologyList iPhone 11\n"
     ]
    }
   ],
   "source": [
    "match_id, start, end = matches[0]\n",
    "print(nlp.vocab.strings[match_id], text_doc[start:end])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token number 17: iPhone 11\n",
      "Token number 22: iPhone 11\n",
      "Token number 30: iPhone 11\n",
      "Token number 33: iPhone 11\n"
     ]
    }
   ],
   "source": [
    "for match in matches:\n",
    "   print(f\"Token number {match[1]}: {text_doc[start:end]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "New Exercise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                   review_id                 user_id             business_id  \\\n109   lDJIaF4eYRF4F7g6Zb9euw  lb0QUR5bc4O-Am4hNq9ZGg  r5PLDU-4mSbde5XekTXSCA   \n1013  vvIzf3pr8lTqE_AOsxmgaA  MAmijW4ooUzujkufYYLMeQ  r5PLDU-4mSbde5XekTXSCA   \n1204  UF-JqzMczZ8vvp_4tPK3bQ  slfi6gf_qEYTXy90Sw93sg  r5PLDU-4mSbde5XekTXSCA   \n1251  geUJGrKhXynxDC2uvERsLw  N_-UepOzAsuDQwOUtfRFGw  r5PLDU-4mSbde5XekTXSCA   \n1354  aPctXPeZW3kDq36TRm-CqA  139hD7gkZVzSvSzDPwhNNw  r5PLDU-4mSbde5XekTXSCA   \n\n      stars  useful  funny  cool  \\\n109       4       2      0     0   \n1013      4       0      0     0   \n1204      5       1      0     0   \n1251      1       0      0     0   \n1354      2       0      0     0   \n\n                                                   text                date  \n109   I used to work food service and my manager at ... 2013-01-27 17:54:54  \n1013  We have been trying Eggplant sandwiches all ov... 2015-04-15 04:50:56  \n1204  Amazing Steak and Cheese... Better than any Ph... 2011-03-20 00:57:45  \n1251  Although I have been going to DeFalco's for ye... 2018-07-17 01:48:23  \n1354  Highs: Ambience, value, pizza and deserts. Thi... 2018-01-21 10:52:58  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>user_id</th>\n      <th>business_id</th>\n      <th>stars</th>\n      <th>useful</th>\n      <th>funny</th>\n      <th>cool</th>\n      <th>text</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>109</th>\n      <td>lDJIaF4eYRF4F7g6Zb9euw</td>\n      <td>lb0QUR5bc4O-Am4hNq9ZGg</td>\n      <td>r5PLDU-4mSbde5XekTXSCA</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>I used to work food service and my manager at ...</td>\n      <td>2013-01-27 17:54:54</td>\n    </tr>\n    <tr>\n      <th>1013</th>\n      <td>vvIzf3pr8lTqE_AOsxmgaA</td>\n      <td>MAmijW4ooUzujkufYYLMeQ</td>\n      <td>r5PLDU-4mSbde5XekTXSCA</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>We have been trying Eggplant sandwiches all ov...</td>\n      <td>2015-04-15 04:50:56</td>\n    </tr>\n    <tr>\n      <th>1204</th>\n      <td>UF-JqzMczZ8vvp_4tPK3bQ</td>\n      <td>slfi6gf_qEYTXy90Sw93sg</td>\n      <td>r5PLDU-4mSbde5XekTXSCA</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Amazing Steak and Cheese... Better than any Ph...</td>\n      <td>2011-03-20 00:57:45</td>\n    </tr>\n    <tr>\n      <th>1251</th>\n      <td>geUJGrKhXynxDC2uvERsLw</td>\n      <td>N_-UepOzAsuDQwOUtfRFGw</td>\n      <td>r5PLDU-4mSbde5XekTXSCA</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Although I have been going to DeFalco's for ye...</td>\n      <td>2018-07-17 01:48:23</td>\n    </tr>\n    <tr>\n      <th>1354</th>\n      <td>aPctXPeZW3kDq36TRm-CqA</td>\n      <td>139hD7gkZVzSvSzDPwhNNw</td>\n      <td>r5PLDU-4mSbde5XekTXSCA</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Highs: Ambience, value, pizza and deserts. Thi...</td>\n      <td>2018-01-21 10:52:58</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_json('resturant.json')\n",
    "data.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# List of menu items and common alternative spellings\n",
    "menu = [\"Cheese Steak\", \"Cheesesteak\", \"Steak and Cheese\", \"Italian Combo\", \"Tiramisu\", \"Cannoli\",\n",
    "        \"Chicken Salad\", \"Chicken Spinach Salad\", \"Meatball\", \"Pizza\", \"Pizzas\", \"Spaghetti\",\n",
    "        \"Bruchetta\", \"Eggplant\", \"Italian Beef\", \"Purista\", \"Pasta\", \"Calzones\",  \"Calzone\",\n",
    "        \"Italian Sausage\", \"Chicken Cutlet\", \"Chicken Parm\", \"Chicken Parmesan\", \"Gnocchi\",\n",
    "        \"Chicken Pesto\", \"Turkey Sandwich\", \"Turkey Breast\", \"Ziti\", \"Portobello\", \"Reuben\",\n",
    "        \"Mozzarella Caprese\",  \"Corned Beef\", \"Garlic Bread\", \"Pastrami\", \"Roast Beef\",\n",
    "        \"Tuna Salad\", \"Lasagna\", \"Artichoke Salad\", \"Fettuccini Alfredo\", \"Chicken Parmigiana\",\n",
    "        \"Grilled Veggie\", \"Grilled Veggies\", \"Grilled Vegetable\", \"Mac and Cheese\", \"Macaroni\",\n",
    "         \"Prosciutto\", \"Salami\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plan the Analysis\n",
    "You could group reviews by what menu items they mention,\n",
    "and then calculate the average rating for reviews that mentioned each item.\n",
    "You can tell which foods are mentioned in reviews with low scores,\n",
    "so the restaurant can fix the recipe or remove those foods from the menu."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8291075388056826051, 2, 3), (8291075388056826051, 16, 17), (8291075388056826051, 58, 59)]\n"
     ]
    }
   ],
   "source": [
    "# Creating for one review\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "index_of_review_to_test_on = 14\n",
    "text_to_test_on = data.text.iloc[index_of_review_to_test_on]\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "# Create the tokenized version of text_to_test_on\n",
    "review_doc = nlp(text_to_test_on)\n",
    "\n",
    "# Create the PhraseMatcher object. The tokenizer is the first argument. Use attr = 'LOWER' to make consistent capitalization\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "# print(matcher)\n",
    "# Create a list of tokens for each item in the menu\n",
    "menu_tokens_list = [nlp(item) for item in menu]\n",
    "\n",
    "# Add the item patterns to the matcher.\n",
    "# Look at https://spacy.io/api/phrasematcher#add in the docs for help with this step\n",
    "# Then uncomment the lines below\n",
    "\n",
    "#\n",
    "matcher.add(\"MENU\",            # Just a name for the set of rules we're matching to\n",
    "           menu_tokens_list\n",
    "          )\n",
    "\n",
    "# Find matches in the review_doc\n",
    "matches = matcher(review_doc)\n",
    "print(matches)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Il Purista sandwich has become a staple of my life. Mozzarella, basil, prosciutto, roasted red peppers and balsamic vinaigrette blend into a front runner for the best sandwich in the valley. Goes great with sparkling water or a beer. \n",
      "\n",
      "DeFalco's also has other Italian fare such as a delicious meatball sub and classic pastas.\n",
      "Token number 2: Purista\n",
      "Token number 16: prosciutto\n",
      "Token number 58: meatball\n"
     ]
    }
   ],
   "source": [
    "print(review_doc)\n",
    "for match in matches:\n",
    "   print(f\"Token number {match[1]}: {review_doc[match[1]:match[2]]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Matching on Whole Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# item_ratings is a dictionary of lists. If a key doesn't exist in item_ratings,\n",
    "# the key is added with an empty list as the value.\n",
    "item_ratings = defaultdict(list)\n",
    "\n",
    "for idx, review in data.iterrows():\n",
    "    doc = nlp(review.text)\n",
    "    # Using the matcher from the previous exercise\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    # Create a set of the items found in the review text\n",
    "    found_items = set([doc[match[1]:match[2]].lower_ for match in matches])\n",
    "\n",
    "    # Update item_ratings with rating for each item in found_items\n",
    "    # Transform the item strings to lowercase to make it case insensitive\n",
    "    for item in found_items:\n",
    "        item_ratings[item].append(review.stars)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# item_ratings\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Calculate the mean ratings for each menu item as a dictionary\n",
    "mean_ratings = {item:sum(ratings)/len(ratings) for item, ratings in item_ratings.items()}\n",
    "\n",
    "# Find the worst item, and write it as a string in worst_item. This can be multiple lines of code if you want.\n",
    "worst_item = sorted(mean_ratings, key=mean_ratings.get)[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items with worst ratigs chicken cutlet\n",
      "items with mean ratings 3.4\n"
     ]
    }
   ],
   "source": [
    "print(\"items with worst ratigs {}\".format(worst_item))\n",
    "print(\"items with mean ratings {}\".format(mean_ratings[worst_item]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    pizza  265\n",
      "                    pasta  206\n",
      "                 meatball  128\n",
      "              cheesesteak   97\n",
      "             cheese steak   76\n",
      "                  cannoli   72\n",
      "                  calzone   72\n",
      "                 eggplant   69\n",
      "                  purista   63\n",
      "                  lasagna   59\n",
      "          italian sausage   53\n",
      "               prosciutto   50\n",
      "             chicken parm   50\n",
      "             garlic bread   39\n",
      "                  gnocchi   37\n",
      "                spaghetti   36\n",
      "                 calzones   35\n",
      "                   pizzas   32\n",
      "                   salami   28\n",
      "            chicken pesto   27\n",
      "             italian beef   25\n",
      "            italian combo   21\n",
      "                 tiramisu   21\n",
      "                     ziti   21\n",
      "         chicken parmesan   19\n",
      "       chicken parmigiana   17\n",
      "               portobello   14\n",
      "           mac and cheese   11\n",
      "           chicken cutlet   10\n",
      "         steak and cheese    9\n",
      "                 pastrami    9\n",
      "               roast beef    7\n",
      "       fettuccini alfredo    6\n",
      "           grilled veggie    6\n",
      "          turkey sandwich    5\n",
      "               tuna salad    5\n",
      "          artichoke salad    5\n",
      "                 macaroni    5\n",
      "            chicken salad    5\n",
      "                   reuben    4\n",
      "    chicken spinach salad    2\n",
      "              corned beef    2\n",
      "            turkey breast    1\n"
     ]
    }
   ],
   "source": [
    "counts = {item: len(ratings) for item, ratings in item_ratings.items()}\n",
    "item_counts = sorted(counts, key=counts.get, reverse=True)\n",
    "for item in item_counts:\n",
    "    print(f\"{item:>25}{counts[item]:>5}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst rated menu items:\n",
      "chicken cutlet       Ave rating: 3.40 \tcount: 10\n",
      "turkey sandwich      Ave rating: 3.80 \tcount: 5\n",
      "spaghetti            Ave rating: 3.89 \tcount: 36\n",
      "italian beef         Ave rating: 3.92 \tcount: 25\n",
      "tuna salad           Ave rating: 4.00 \tcount: 5\n",
      "macaroni             Ave rating: 4.00 \tcount: 5\n",
      "italian combo        Ave rating: 4.05 \tcount: 21\n",
      "garlic bread         Ave rating: 4.13 \tcount: 39\n",
      "roast beef           Ave rating: 4.14 \tcount: 7\n",
      "eggplant             Ave rating: 4.16 \tcount: 69\n",
      "\n",
      "\n",
      "Best rated menu items:\n",
      "chicken pesto        Ave rating: 4.56 \tcount: 27\n",
      "chicken salad        Ave rating: 4.60 \tcount: 5\n",
      "purista              Ave rating: 4.67 \tcount: 63\n",
      "prosciutto           Ave rating: 4.68 \tcount: 50\n",
      "reuben               Ave rating: 4.75 \tcount: 4\n",
      "steak and cheese     Ave rating: 4.89 \tcount: 9\n",
      "artichoke salad      Ave rating: 5.00 \tcount: 5\n",
      "fettuccini alfredo   Ave rating: 5.00 \tcount: 6\n",
      "turkey breast        Ave rating: 5.00 \tcount: 1\n",
      "corned beef          Ave rating: 5.00 \tcount: 2\n"
     ]
    }
   ],
   "source": [
    "sorted_ratings = sorted(mean_ratings, key=mean_ratings.get)\n",
    "\n",
    "print(\"Worst rated menu items:\")\n",
    "for item in sorted_ratings[:10]:\n",
    "    print(f\"{item:20} Ave rating: {mean_ratings[item]:.2f} \\tcount: {counts[item]}\")\n",
    "\n",
    "print(\"\\n\\nBest rated menu items:\")\n",
    "for item in sorted_ratings[-10:]:\n",
    "    print(f\"{item:20} Ave rating: {mean_ratings[item]:.2f} \\tcount: {counts[item]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}